### How Far Are We to GPT-4V
## By Alexander
# This paper was writen by OpenGVlab.
this paper was write to explain how far are we to GPT-4V just like title.
It mainly told us how InternVL1.5 works and many aspects compared to GPT-4V
This model is a multimodal models(MLLMs) that aims to understanding different images and texts.
This model mainly have 3 features:
# Strong Vision Encoder
# Dynamic High-Resolution
# High-Quality Bilingual Dataset
